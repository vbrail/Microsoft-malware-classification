{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "# import matplotlib\n",
    "# matplotlib.use(u'nbAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from multiprocessing import Process# this is used for multithreading\n",
    "import multiprocessing\n",
    "import codecs# this is used for file operations \n",
    "import random as r\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime as dt\n",
    "import imageio\n",
    "import array\n",
    "import gc\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training(models , hyper_param,X_train,Y_train,x_cv,y_cv,x_test,y_test):\n",
    "    min_cv_loss_value = {}\n",
    "    min_cv_loss_param = {}\n",
    "    train_loss  = {}\n",
    "    cv_loss     = {}\n",
    "    for model_name in models.keys():\n",
    "        train_loss[model_name] = []\n",
    "        cv_loss[model_name]    = []\n",
    "        print('------------------------------->'+model_name+'<----------------------------------')\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "        for param in hyper_param[model_name]:\n",
    "            print('MODEL : '+model_name+'    '+list(param.keys())[0]+' : ',list(param.values())[0])\n",
    "            model = models[model_name]\n",
    "            model.set_params(**param)\n",
    "            print('Training started... ')\n",
    "            st = dt.now()\n",
    "            model.fit(x_train, y_train)\n",
    "            sig_clf = CalibratedClassifierCV(model, method=\"sigmoid\")\n",
    "            sig_clf.fit(x_train, y_train)\n",
    "            print('Time taken : ',dt.now()-st)\n",
    "            cv_pred  = sig_clf.predict_proba(x_cv)\n",
    "            tr_pred  = sig_clf.predict_proba(x_train)\n",
    "            c_loss   = log_loss(y_cv, cv_pred, labels=model.classes_, eps=1e-15)\n",
    "            tr_loss  = log_loss(y_train, tr_pred, labels=model.classes_, eps=1e-15)\n",
    "            print('Train loss : ',tr_loss)\n",
    "            print('CV loss    : ',c_loss)\n",
    "            train_loss[model_name].append(tr_loss)\n",
    "            cv_loss[model_name].append(c_loss)\n",
    "            print('-------------------------------------------')\n",
    "        min_loss = min(cv_loss[model_name])\n",
    "        min_cv_loss_value[model_name] = min(cv_loss[model_name])\n",
    "        min_cv_loss_param[model_name] = list(hyper_param[model_name][np.argmin(cv_loss[model_name])].values())[0]\n",
    "    print('\\n\\n\\n\\n-----------------------------Summary------------------------------------')\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    print('Model Name                 Best Hyper-param               Min-loss       ')\n",
    "    print('-------------------------------------------------------------------------')\n",
    "    for model_name in models:\n",
    "        print(model_name,'                  ',min_cv_loss_param[model_name],'                 ',min_cv_loss_value[model_name])\n",
    "        print('-------------------------------------------------------------------------')\n",
    "        \n",
    "    print('\\n\\n\\n\\n')\n",
    "    print('--------------Training & testing models with best hyper-parameter found ------------------')\n",
    "    for model_name in models:\n",
    "        print('--------------------->'+model_name+'<------------------------------------')\n",
    "        print('-------------------------------------------------------------------------')\n",
    "        model = models[model_name]\n",
    "        model.set_params(**{list(hyper_param[model_name][0].keys())[0]:min_cv_loss_param[model_name]})        \n",
    "        model.fit(X_train, Y_train)\n",
    "        sig_clf = CalibratedClassifierCV(model, method=\"sigmoid\")\n",
    "        sig_clf.fit(X_train, Y_train)\n",
    "        te_pred  = sig_clf.predict_proba(x_test)\n",
    "        tr_pred  = sig_clf.predict_proba(X_train)\n",
    "        te_loss   = log_loss(y_test, te_pred, labels=model.classes_, eps=1e-15)\n",
    "        tr_loss  = log_loss(Y_train, tr_pred, labels=model.classes_, eps=1e-15)\n",
    "        print('Train loss : ',tr_loss)\n",
    "        print('Test loss    : ',te_loss)\n",
    "        print('------------------------------------------------------------------------')\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('feature_array.pickle', 'rb') as fr:\n",
    "    data = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.load('traindata/class_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, Y_train, y_test = train_test_split(data, label,stratify=label,test_size=0.20)\n",
    "x_train, x_cv, y_train, y_cv     = train_test_split(X_train, Y_train,stratify=Y_train,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_param = {'KNN':        [ {'n_neighbors':v}   for v in range(1, 15, 2)],\n",
    "               'LR' :        [ {'C':10 ** v}       for v in range(-3, 3)],\n",
    "               'RF' :        [ {'n_estimators':v}  for v in [10,50,100,500,1000,2000]],\n",
    "               'XGB':        [ {'n_estimators':v}  for v in [10,50,100,500,1000,2000]]    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model    =   {'KNN'    : KNeighborsClassifier(n_jobs=-1),\n",
    "              'LR'     : LogisticRegression(penalty='l2',class_weight='balanced',n_jobs=-1),\n",
    "              'RF'     : RandomForestClassifier(random_state=42,n_jobs=-1),\n",
    "              'XGB'    : XGBClassifier(nthread=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------->KNN<----------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "MODEL : KNN    n_neighbors :  1\n",
      "Training started... \n",
      "Time taken :  0:00:07.478967\n",
      "Train loss :  0.0800293655901065\n",
      "CV loss    :  0.23420294993544127\n",
      "-------------------------------------------\n",
      "MODEL : KNN    n_neighbors :  3\n",
      "Training started... \n",
      "Time taken :  0:00:08.288827\n",
      "Train loss :  0.12718192042843282\n",
      "CV loss    :  0.2399507605498237\n",
      "-------------------------------------------\n",
      "MODEL : KNN    n_neighbors :  5\n",
      "Training started... \n",
      "Time taken :  0:00:08.705395\n",
      "Train loss :  0.17150867468507078\n",
      "CV loss    :  0.26104651185399114\n",
      "-------------------------------------------\n",
      "MODEL : KNN    n_neighbors :  7\n",
      "Training started... \n",
      "Time taken :  0:00:09.028820\n",
      "Train loss :  0.20559195801423316\n",
      "CV loss    :  0.28289734681623735\n",
      "-------------------------------------------\n",
      "MODEL : KNN    n_neighbors :  9\n",
      "Training started... \n",
      "Time taken :  0:00:09.225924\n",
      "Train loss :  0.23317064639476887\n",
      "CV loss    :  0.30252635754637475\n",
      "-------------------------------------------\n",
      "MODEL : KNN    n_neighbors :  11\n",
      "Training started... \n",
      "Time taken :  0:00:09.472085\n",
      "Train loss :  0.25340070275250376\n",
      "CV loss    :  0.3157923173924745\n",
      "-------------------------------------------\n",
      "MODEL : KNN    n_neighbors :  13\n",
      "Training started... \n",
      "Time taken :  0:00:09.401194\n",
      "Train loss :  0.2709403879637625\n",
      "CV loss    :  0.32819628616534124\n",
      "-------------------------------------------\n",
      "------------------------------->RF<----------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "MODEL : RF    n_estimators :  10\n",
      "Training started... \n",
      "Time taken :  0:00:03.393019\n",
      "Train loss :  0.01910827967689163\n",
      "CV loss    :  0.03912784023225763\n",
      "-------------------------------------------\n",
      "MODEL : RF    n_estimators :  50\n",
      "Training started... \n",
      "Time taken :  0:00:04.873748\n",
      "Train loss :  0.015238325121006684\n",
      "CV loss    :  0.0299134889706194\n",
      "-------------------------------------------\n",
      "MODEL : RF    n_estimators :  100\n",
      "Training started... \n",
      "Time taken :  0:00:06.429113\n",
      "Train loss :  0.014871059389727695\n",
      "CV loss    :  0.02851111116788793\n",
      "-------------------------------------------\n",
      "MODEL : RF    n_estimators :  500\n",
      "Training started... \n",
      "Time taken :  0:00:21.636827\n",
      "Train loss :  0.014440850251895527\n",
      "CV loss    :  0.02894739481029194\n",
      "-------------------------------------------\n",
      "MODEL : RF    n_estimators :  1000\n",
      "Training started... \n",
      "Time taken :  0:00:41.115251\n",
      "Train loss :  0.014462932401403382\n",
      "CV loss    :  0.02841731637755972\n",
      "-------------------------------------------\n",
      "MODEL : RF    n_estimators :  2000\n",
      "Training started... \n",
      "Time taken :  0:01:18.699057\n",
      "Train loss :  0.014428096288226276\n",
      "CV loss    :  0.028256618344262435\n",
      "-------------------------------------------\n",
      "------------------------------->XGB<----------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "MODEL : XGB    n_estimators :  10\n",
      "Training started... \n",
      "Time taken :  0:00:32.783872\n",
      "Train loss :  0.04242774201246192\n",
      "CV loss    :  0.050542496161399414\n",
      "-------------------------------------------\n",
      "MODEL : XGB    n_estimators :  50\n",
      "Training started... \n",
      "Time taken :  0:02:19.217623\n",
      "Train loss :  0.016843533650916512\n",
      "CV loss    :  0.02538515523477001\n",
      "-------------------------------------------\n",
      "MODEL : XGB    n_estimators :  100\n",
      "Training started... \n",
      "Time taken :  0:04:19.778403\n",
      "Train loss :  0.012255102263209172\n",
      "CV loss    :  0.019742611450784632\n",
      "-------------------------------------------\n",
      "MODEL : XGB    n_estimators :  500\n",
      "Training started... \n",
      "Time taken :  0:13:05.873368\n",
      "Train loss :  0.011982177112454171\n",
      "CV loss    :  0.020707926028435457\n",
      "-------------------------------------------\n",
      "MODEL : XGB    n_estimators :  1000\n",
      "Training started... \n",
      "Time taken :  0:21:53.986288\n",
      "Train loss :  0.012026161913548761\n",
      "CV loss    :  0.02086017648030029\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------Summary------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "Model Name                 Best Hyper-param               Min-loss       \n",
      "-------------------------------------------------------------------------\n",
      "KNN                    1                   0.23420294993544127\n",
      "-------------------------------------------------------------------------\n",
      "RF                    2000                   0.028256618344262435\n",
      "-------------------------------------------------------------------------\n",
      "XGB                    100                   0.019742611450784632\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------Training & testing models with best hyper-parameter found ------------------\n",
      "--------------------->KNN<------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "Train loss :  0.06896326800666754\n",
      "Test loss    :  0.23623477404025073\n",
      "------------------------------------------------------------------------\n",
      "--------------------->RF<------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "Train loss :  0.011394147909761254\n",
      "Test loss    :  0.029700686125839756\n",
      "------------------------------------------------------------------------\n",
      "--------------------->XGB<------------------------------------\n",
      "-------------------------------------------------------------------------\n",
      "Train loss :  0.008262628521035266\n",
      "Test loss    :  0.023271058503435256\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Training(model,hyper_param,X_train,Y_train,x_cv,y_cv,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed: 28.2min remaining: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed: 31.0min remaining:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed: 34.4min remaining:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 36.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_state=0, reg_al...\n",
       "                                           seed=None, silent=None, subsample=1,\n",
       "                                           verbosity=1),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.1, 0.3, 0.5, 1],\n",
       "                                        'learning_rate': [0.01, 0.03, 0.05, 0.1,\n",
       "                                                          0.15, 0.2],\n",
       "                                        'max_depth': [3, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 500, 1000],\n",
       "                                        'subsample': [0.1, 0.3, 0.5, 1]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xgb Hyperparameter tunning with morehyperparameter\n",
    "x_cfl=XGBClassifier()\n",
    "prams={\n",
    "    'learning_rate':[0.01,0.03,0.05,0.1,0.15,0.2],\n",
    "     'n_estimators':[100,200,500,1000],\n",
    "     'max_depth':[3,5,10],\n",
    "    'colsample_bytree':[0.1,0.3,0.5,1],\n",
    "    'subsample':[0.1,0.3,0.5,1]\n",
    "}\n",
    "model=RandomizedSearchCV(x_cfl,param_distributions=prams,verbose=10,n_jobs=-1,)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 1, 'n_estimators': 1000, 'colsample_bytree': 0.1, 'learning_rate': 0.05, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "# best \n",
    "print (model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.010177294642082986\n",
      "cv loss 0.019253526056368753\n",
      "test loss 0.02508257442005977\n"
     ]
    }
   ],
   "source": [
    "clf=XGBClassifier(n_estimators=1000, learning_rate=0.05, colsample_bytree=0.1, max_depth=3)\n",
    "clf.fit(x_train,y_train)\n",
    "model=CalibratedClassifierCV(clf,method='sigmoid')\n",
    "model.fit(x_train,y_train)\n",
    "pred_y = model.predict_proba(x_train)\n",
    "print ('train loss',log_loss(y_train, pred_y))\n",
    "pred_y = model.predict_proba(x_cv)\n",
    "print ('cv loss',log_loss(y_cv, pred_y))\n",
    "pred_y = model.predict_proba(x_test)\n",
    "print ('test loss',log_loss(y_test, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just above is not best result the best result we got in the training function which is 0.023 with xgb with 100 base estimater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
